"""Agent loop: the core processing engine."""

import asyncio
import json
from collections import Counter
from pathlib import Path
from typing import Any

from loguru import logger

from nanobot.bus.events import InboundMessage, OutboundMessage
from nanobot.bus.queue import MessageBus
from nanobot.providers.base import LLMProvider
from nanobot.agent.context import ContextBuilder
from nanobot.agent.tools.registry import ToolRegistry
from nanobot.agent.tools.filesystem import ReadFileTool, WriteFileTool, EditFileTool, ListDirTool
from nanobot.agent.tools.shell import ExecTool
from nanobot.agent.tools.web import WebSearchTool, WebFetchTool, OllamaWebSearchTool
from nanobot.agent.tools.message import MessageTool
from nanobot.agent.tools.spawn import SpawnTool
from nanobot.agent.tools.memory import RememberTool, RecallTool, SearchMemoryTool
from nanobot.agent.memory import MemoryStore
from nanobot.agent.subagent import SubagentManager
from nanobot.session.manager import SessionManager
from nanobot.usage.tracker import UsageTracker


class AgentLoop:
    """
    The agent loop is the core processing engine.
    
    It:
    1. Receives messages from the bus
    2. Builds context with history, memory, skills
    3. Calls the LLM
    4. Executes tool calls
    5. Sends responses back
    """
    
    def __init__(
        self,
        bus: MessageBus,
        provider: LLMProvider,
        workspace: Path,
        model: str | None = None,
        max_iterations: int = 20,
        brave_api_key: str | None = None,
        ollama_web_search_key: str | None = None,
        ollama_web_search_base_url: str | None = None,
        exec_config: "ExecToolConfig | None" = None,
        usage_alert_config: "UsageAlertConfig | None" = None,
        memory_config: "MemoryConfig | None" = None,
    ):
        from nanobot.config.schema import ExecToolConfig, UsageAlertConfig, MemoryConfig
        self.bus = bus
        self.provider = provider
        self.workspace = workspace
        self.model = model or provider.get_default_model()
        self.max_iterations = max_iterations
        self.brave_api_key = brave_api_key
        self.ollama_web_search_key = ollama_web_search_key
        self.ollama_web_search_base_url = ollama_web_search_base_url or "https://ollama.com"
        self.exec_config = exec_config or ExecToolConfig()
        self.usage_alert_config = usage_alert_config or UsageAlertConfig()
        self.memory_config = memory_config or MemoryConfig()
        
        self.context = ContextBuilder(workspace)
        self.sessions = SessionManager(workspace)
        self.memory = MemoryStore(workspace, llm_provider=provider, config=self.memory_config)
        self.tools = ToolRegistry()
        self.usage_tracker = UsageTracker()
        self.subagents = SubagentManager(
            provider=provider,
            workspace=workspace,
            bus=bus,
            model=self.model,
            brave_api_key=brave_api_key,
            exec_config=self.exec_config,
        )
        
        self._running = False
        self._register_default_tools()
    
    def _check_usage_alerts(self, session_key: str) -> str | None:
        """
        Check if usage limits have been exceeded and return warning message.
        
        Args:
            session_key: Session identifier to check.
        
        Returns:
            Warning message if limits exceeded, None otherwise.
        """
        if not self.usage_alert_config.enabled:
            return None
        
        warnings = []
        
        # Check session limit
        if self.usage_alert_config.session_limit > 0:
            session_usage = self.usage_tracker.get_session(session_key)
            if session_usage:
                total = session_usage.get("total_tokens", 0)
                if total > self.usage_alert_config.session_limit:
                    warnings.append(
                        f"âš ï¸  Session token limit exceeded: {total:,} / {self.usage_alert_config.session_limit:,} tokens"
                    )
        
        # Check daily limit
        if self.usage_alert_config.daily_limit > 0:
            daily_usage = self.usage_tracker.get_daily()
            if daily_usage:
                total = daily_usage.get("total_tokens", 0)
                if total > self.usage_alert_config.daily_limit:
                    warnings.append(
                        f"âš ï¸  Daily token limit exceeded: {total:,} / {self.usage_alert_config.daily_limit:,} tokens"
                    )
        
        if warnings:
            logger.warning(f"Usage alert triggered for {session_key}: {'; '.join(warnings)}")
            return "\n".join(warnings)
        
        return None
    
    def _register_default_tools(self) -> None:
        """Register the default set of tools."""
        # File tools
        self.tools.register(ReadFileTool())
        self.tools.register(WriteFileTool())
        self.tools.register(EditFileTool())
        self.tools.register(ListDirTool())
        
        # Shell tool
        self.tools.register(ExecTool(
            working_dir=str(self.workspace),
            timeout=self.exec_config.timeout,
            restrict_to_workspace=self.exec_config.restrict_to_workspace,
        ))
        
        # Web tools
        if self.brave_api_key:
            self.tools.register(WebSearchTool(api_key=self.brave_api_key))
        
        if self.ollama_web_search_key:
            self.tools.register(OllamaWebSearchTool(
                api_key=self.ollama_web_search_key,
                base_url=self.ollama_web_search_base_url
            ))
        
        self.tools.register(WebFetchTool())
        
        # Message tool
        message_tool = MessageTool(send_callback=self.bus.publish_outbound)
        self.tools.register(message_tool)
        
        # Memory tools
        self.tools.register(RememberTool(memory_store=self.memory))
        self.tools.register(RecallTool(memory_store=self.memory, llm_provider=self.provider))
        self.tools.register(SearchMemoryTool(memory_store=self.memory))
        
        # Spawn tool (for subagents)
        spawn_tool = SpawnTool(manager=self.subagents)
        self.tools.register(spawn_tool)
    
    async def run(self) -> None:
        """Run the agent loop, processing messages from the bus."""
        self._running = True
        logger.info("Agent loop started")
        
        while self._running:
            try:
                # Wait for next message
                msg = await asyncio.wait_for(
                    self.bus.consume_inbound(),
                    timeout=1.0
                )
                
                # Process it
                try:
                    response = await self._process_message(msg)
                    if response:
                        await self.bus.publish_outbound(response)
                except Exception as e:
                    logger.error(f"Error processing message: {e}")
                    # Send error response
                    await self.bus.publish_outbound(OutboundMessage(
                        channel=msg.channel,
                        chat_id=msg.chat_id,
                        content=f"Sorry, I encountered an error: {str(e)}"
                    ))
            except asyncio.TimeoutError:
                continue
    
    def stop(self) -> None:
        """Stop the agent loop."""
        self._running = False
        logger.info("Agent loop stopping")
    
    async def _process_message(self, msg: InboundMessage) -> OutboundMessage | None:
        """
        Process a single inbound message.
        
        Args:
            msg: The inbound message to process.
        
        Returns:
            The response message, or None if no response needed.
        """
        # Handle system messages (subagent announces)
        # The chat_id contains the original "channel:chat_id" to route back to
        if msg.channel == "system":
            return await self._process_system_message(msg)
        
        logger.info(f"Processing message from {msg.channel}:{msg.sender_id}")
        
        # Track tool usage for this session
        tool_calls_counter = Counter()
        
        # Get or create session
        session = self.sessions.get_or_create(msg.session_key)
        
        # Update tool contexts
        message_tool = self.tools.get("message")
        if isinstance(message_tool, MessageTool):
            message_tool.set_context(msg.channel, msg.chat_id)
        
        spawn_tool = self.tools.get("spawn")
        if isinstance(spawn_tool, SpawnTool):
            spawn_tool.set_context(msg.channel, msg.chat_id)
        
        # Build initial messages (use get_history for LLM-formatted messages)
        messages = self.context.build_messages(
            history=session.get_history(),
            current_message=msg.content,
            media=msg.media if msg.media else None,
        )
        
        # Agent loop
        iteration = 0
        final_content = None
        
        while iteration < self.max_iterations:
            iteration += 1
            
            # Call LLM
            response = await self.provider.chat(
                messages=messages,
                tools=self.tools.get_definitions(),
                model=self.model
            )
            
            # Track token usage
            if response.usage:
                self.usage_tracker.track(
                    session_key=msg.session_key,
                    model=self.model,
                    prompt_tokens=response.usage.get("prompt_tokens", 0),
                    completion_tokens=response.usage.get("completion_tokens", 0),
                    total_tokens=response.usage.get("total_tokens", 0),
                )
            
            # Handle tool calls
            if response.has_tool_calls:
                # Add assistant message with tool calls
                tool_call_dicts = [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.name,
                            "arguments": json.dumps(tc.arguments)  # Must be JSON string
                        }
                    }
                    for tc in response.tool_calls
                ]
                messages = self.context.add_assistant_message(
                    messages, response.content, tool_call_dicts
                )
                
                # Execute tools
                for tool_call in response.tool_calls:
                    args_str = json.dumps(tool_call.arguments)
                    logger.debug(f"Executing tool: {tool_call.name} with arguments: {args_str}")
                    result = await self.tools.execute(tool_call.name, tool_call.arguments)
                    messages = self.context.add_tool_result(
                        messages, tool_call.id, tool_call.name, result
                    )
                    # Track tool usage
                    tool_calls_counter[tool_call.name] += 1
            else:
                # No tool calls, we're done
                final_content = response.content
                break
        
        if final_content is None:
            final_content = "I've completed processing but have no response to give."
        
        # Check usage alerts and append warning if needed
        usage_warning = self._check_usage_alerts(msg.session_key)
        if usage_warning:
            final_content = f"{final_content}\n\n{usage_warning}"
        
        # Log tool usage summary
        if tool_calls_counter:
            tool_summary = ", ".join(
                f"{name} ({count}x)" if count > 1 else name
                for name, count in tool_calls_counter.most_common()
            )
            logger.info(f"Tools used: {tool_summary}")
        
        # Auto-extract memories if enabled
        if self.memory_config.auto_extract:
            await self._auto_extract_memories(session)
        
        # Save to session
        session.add_message("user", msg.content)
        session.add_message("assistant", final_content)
        self.sessions.save(session)
        
        return OutboundMessage(
            channel=msg.channel,
            chat_id=msg.chat_id,
            content=final_content
        )
    
    async def _process_system_message(self, msg: InboundMessage) -> OutboundMessage | None:
        """
        Process a system message (e.g., subagent announce).
        
        The chat_id field contains "original_channel:original_chat_id" to route
        the response back to the correct destination.
        """
        logger.info(f"Processing system message from {msg.sender_id}")
        
        # Parse origin from chat_id (format: "channel:chat_id")
        if ":" in msg.chat_id:
            parts = msg.chat_id.split(":", 1)
            origin_channel = parts[0]
            origin_chat_id = parts[1]
        else:
            # Fallback
            origin_channel = "cli"
            origin_chat_id = msg.chat_id
        
        # Use the origin session for context
        session_key = f"{origin_channel}:{origin_chat_id}"
        session = self.sessions.get_or_create(session_key)
        
        # Update tool contexts
        message_tool = self.tools.get("message")
        if isinstance(message_tool, MessageTool):
            message_tool.set_context(origin_channel, origin_chat_id)
        
        spawn_tool = self.tools.get("spawn")
        if isinstance(spawn_tool, SpawnTool):
            spawn_tool.set_context(origin_channel, origin_chat_id)
        
        # Build messages with the announce content
        messages = self.context.build_messages(
            history=session.get_history(),
            current_message=msg.content
        )
        
        # Agent loop (limited for announce handling)
        iteration = 0
        final_content = None
        
        while iteration < self.max_iterations:
            iteration += 1
            
            response = await self.provider.chat(
                messages=messages,
                tools=self.tools.get_definitions(),
                model=self.model
            )
            
            # Track token usage for system messages
            if response.usage:
                self.usage_tracker.track(
                    session_key=session_key,
                    model=self.model,
                    prompt_tokens=response.usage.get("prompt_tokens", 0),
                    completion_tokens=response.usage.get("completion_tokens", 0),
                    total_tokens=response.usage.get("total_tokens", 0),
                )
            
            if response.has_tool_calls:
                tool_call_dicts = [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.name,
                            "arguments": json.dumps(tc.arguments)
                        }
                    }
                    for tc in response.tool_calls
                ]
                messages = self.context.add_assistant_message(
                    messages, response.content, tool_call_dicts
                )
                
                for tool_call in response.tool_calls:
                    args_str = json.dumps(tool_call.arguments)
                    logger.debug(f"Executing tool: {tool_call.name} with arguments: {args_str}")
                    result = await self.tools.execute(tool_call.name, tool_call.arguments)
                    messages = self.context.add_tool_result(
                        messages, tool_call.id, tool_call.name, result
                    )
            else:
                final_content = response.content
                break
        
        if final_content is None:
            final_content = "Background task completed."
        
        # Save to session (mark as system message in history)
        session.add_message("user", f"[System: {msg.sender_id}] {msg.content}")
        session.add_message("assistant", final_content)
        self.sessions.save(session)
        
        return OutboundMessage(
            channel=origin_channel,
            chat_id=origin_chat_id,
            content=final_content
        )
    
    async def process_direct(self, content: str, session_key: str = "cli:direct") -> str:
        """
        Process a message directly (for CLI usage).
        
        Args:
            content: The message content.
            session_key: Session identifier.
        
        Returns:
            The agent's response.
        """
        msg = InboundMessage(
            channel="cli",
            sender_id="user",
            chat_id="direct",
            content=content
        )
        
        response = await self._process_message(msg)
        return response.content if response else ""
    
    async def _auto_extract_memories(self, session: "Session") -> None:
        """
        Automatically extract and save important memories from the conversation.
        
        This runs after each conversation turn if auto_extract is enabled.
        Uses smart extraction and Mem0-inspired lifecycle management to
        avoid duplicates and contradictions.
        
        Args:
            session: The conversation session to extract from.
        """
        try:
            # Get recent conversation history (last 6 messages)
            history = session.get_history()
            if len(history) < 2:
                return  # Not enough conversation
            
            recent_messages = history[-6:]
            
            # Convert to format expected by smart_extract
            conversation = [
                {"role": msg.get("role", "user"), "content": msg.get("content", "")}
                for msg in recent_messages
            ]
            
            # Extract facts
            max_facts = self.memory_config.max_facts_per_extraction
            facts = await self.memory.smart_extract(conversation, max_facts=max_facts)
            
            if not facts:
                logger.debug("No facts extracted from conversation")
                return
            
            # Optionally deduplicate
            if self.memory_config.smart_dedupe:
                facts = await self.memory.smart_dedupe(facts)
            
            # Use lifecycle management if enabled
            if self.memory_config.enable_lifecycle and hasattr(self.memory, 'lifecycle_update'):
                try:
                    result = await self.memory.lifecycle_update(
                        new_facts=facts,
                        category="auto_extracted"
                    )
                    
                    # Log lifecycle actions
                    added = len(result.get("add", []))
                    updated = len(result.get("update", []))
                    deleted = len(result.get("delete", []))
                    skipped = len(result.get("noop", []))
                    
                    logger.info(
                        f"Memory lifecycle: {added} added, {updated} updated, "
                        f"{deleted} deleted, {skipped} skipped"
                    )
                    return
                    
                except Exception as e:
                    logger.warning(f"Lifecycle update failed, falling back to simple append: {e}")
            
            # Fallback: save facts to daily notes
            for fact in facts:
                from datetime import datetime
                timestamp = datetime.now().strftime("%H:%M")
                entry = f"- [{timestamp}] ðŸ¤– Auto-extracted: {fact}"
                self.memory.append_today(entry)
            
            logger.info(f"Auto-extracted {len(facts)} memory facts")
            
        except Exception as e:
            logger.error(f"Auto memory extraction failed: {e}")
